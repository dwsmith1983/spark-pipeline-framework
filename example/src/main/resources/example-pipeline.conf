# Example pipeline configuration
# Run with: spark-submit --class com.example.spark.pipeline.runner.SimplePipelineRunner \
#           --jars example.jar runner.jar -Dconfig.file=example-pipeline.conf

spark {
  # master = "local[*]"  # Uncomment for local testing
  app-name = "Example Pipeline"

  config {
    "spark.sql.adaptive.enabled" = "true"
    "spark.sql.adaptive.coalescePartitions.enabled" = "true"
  }
}

pipeline {
  pipeline-name = "Example Data Pipeline"

  pipeline-components = [
    {
      instance-type = "com.example.pipelines.WordCount"
      instance-name = "WordCount(example)"
      instance-config {
        input-path = "/data/input/text"
        output-path = "/data/output/wordcount"
        min-count = 5
        write-format = "parquet"
      }
    },
    {
      instance-type = "com.example.pipelines.TableTransform"
      instance-name = "TableTransform(users)"
      instance-config {
        input-table = "default.users"
        output-path = "/data/output/active_users"
        select-columns = ["id", "name", "email", "created_at"]
        filter-condition = "active = true"
        write-format = "parquet"
        write-mode = "overwrite"
      }
    }
  ]
}
